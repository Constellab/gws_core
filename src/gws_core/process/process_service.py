

import threading
import time
from datetime import datetime, timedelta
from typing import Dict, List, Literal, Type

import schedule
from gws_core.community.community_service import CommunityService
from gws_core.core.exception.exceptions.bad_request_exception import \
    BadRequestException
from gws_core.core.utils.date_helper import DateHelper
from gws_core.core.utils.logger import Logger
from gws_core.lab.log.log import LogsBetweenDates
from gws_core.lab.log.log_service import LogService
from gws_core.lab.monitor.monitor_dto import MonitorBetweenDateGraphicsDTO
from gws_core.lab.monitor.monitor_service import MonitorService
from gws_core.process.process_model import ProcessModel
from gws_core.process.process_types import ProcessStatus
from gws_core.process_run_stat.process_run_stat_model import \
    ProcessRunStatModel
from gws_core.protocol.protocol_model import ProtocolModel
from gws_core.task.task_model import TaskModel

ProcessType = Literal['TASK', 'PROTOCOL']


class ProcessService:

    # add a margin of 2 seconds to avoid missing the first log lines and the last log lines
    LOG_SECOND_MARGIN = 2

    @classmethod
    def get_logs_of_process(
            cls, process_type: ProcessType, process_id: str, from_page_date: datetime = None) -> LogsBetweenDates:
        """Read the server log on filtered by the process start and end date
        """
        process_model: ProcessModel = cls.get_and_check_process_model(process_type, process_id)

        if process_model.status == ProcessStatus.DRAFT:
            raise BadRequestException("Can't get logs of a process in draft status")

        start_date: datetime = None
        # if a page date is given, use it (it is when we load a new page)
        if from_page_date:
            start_date = from_page_date
        else:
            # add a margin of 2 seconds to avoid missing the first log lines and the last log lines
            start_date = process_model.started_at - timedelta(seconds=cls.LOG_SECOND_MARGIN)
        end_date = (process_model.ended_at or DateHelper.now_utc()) + timedelta(seconds=cls.LOG_SECOND_MARGIN)

        # retrieve the log generated by the process during the time
        return LogService.get_logs_between_dates(start_date, end_date, from_scenario_id=process_model.scenario.id)

    @classmethod
    def get_monitor_of_process(cls, process_type: ProcessType, process_id: str, timezone_number: float = 0.0) -> MonitorBetweenDateGraphicsDTO:
        process_model: ProcessModel = cls.get_and_check_process_model(process_type, process_id)

        if process_model.status == ProcessStatus.DRAFT:
            raise BadRequestException("Can't get monitor of a process in draft status")

        from_date = process_model.started_at
        to_date = process_model.ended_at or DateHelper.now_utc()
        return MonitorService.get_monitor_data_graphics_between_dates(from_date, to_date, utc_number=timezone_number)

    @classmethod
    def get_and_check_process_model(cls, process_type: ProcessType, process_id: str) -> ProcessModel:
        process_type: Type[ProcessModel] = cls._get_class_from_type(process_type)
        return process_type.get_by_id_and_check(process_id)

    @classmethod
    def _get_class_from_type(cls, process_type: ProcessType) -> Type[ProcessModel]:
        if process_type == 'TASK':
            return TaskModel
        elif process_type == 'PROTOCOL':
            return ProtocolModel
        else:
            raise BadRequestException(f"Process type {process_type} does not exist")

    @classmethod
    def init_cron_thread_run_stats(cls) -> None:
        """
        Init CRON Thread to send process runs stats to community
        """
        x = threading.Thread(target=cls._thread_send_process_run_stats_to_community)
        x.start()

    @classmethod
    def send_process_run_stats_to_community(cls):
        """
        CRON scheduled method to send run stats to community
        """

        try:
            Logger.debug("Check to send run stats to Community")
            stats = ProcessRunStatModel.select().where(
                ProcessRunStatModel.sync_with_community == False).order_by(
                ProcessRunStatModel.created_at.asc())
            if len(stats) > 0:
                run_stats: List[Dict] = []
                for stat in stats:
                    run_stats.append(stat.to_dto().to_json_dict())
                CommunityService.send_process_run_stats(run_stats)
                for stat in stats:
                    stat.sync_with_community = True
                    stat.save()
        except Exception as err:
            Logger.error("Error sending run statistics to the Community. Error: " + str(err))

    @classmethod
    def _thread_send_process_run_stats_to_community(cls):
        """
        Thread method to send new process run stats to community
        """

        # Send run stats on init to Community then cron to send new process run stats to Community each hours
        ProcessService.send_process_run_stats_to_community()
        # Set and run the scheduled cron method
        schedule.every(1).hours.do(cls.send_process_run_stats_to_community)
        while True:
            schedule.run_pending()
            time.sleep(1)

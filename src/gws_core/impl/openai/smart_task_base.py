# LICENSE
# This software is the exclusive property of Gencovery SAS.
# The use and distribution of this software is prohibited without the prior consent of Gencovery SAS.
# About us: https://gencovery.com
from abc import abstractmethod
from typing import Dict, List

from gws_core.config.config_params import ConfigParams
from gws_core.config.config_types import ConfigSpecs
from gws_core.impl.live.helper.live_code_helper import LiveCodeHelper
from gws_core.impl.openai.open_ai_chat import OpenAiChat
from gws_core.impl.openai.open_ai_chat_param import OpenAiChatParam
from gws_core.impl.openai.open_ai_helper import OpenAiHelper
from gws_core.impl.text.text import Text
from gws_core.io.io_spec import OutputSpec
from gws_core.task.task import Task
from gws_core.task.task_io import TaskInputs, TaskOutputs


class SmartTaskBase(Task):

    generated_code_output = OutputSpec(
        Text, human_name='Generated code',
        short_description='Modified generated code that can be used in a python live task directly.')

    config_specs: ConfigSpecs = {
        'prompt': OpenAiChatParam()
    }

    @abstractmethod
    def get_context(self, params: ConfigParams, inputs: TaskInputs) -> str:
        """Method to build the context of the openAI chat. This context is used to give precise information to the AI to generate the code you want.

        :param params: task params
        :type params: ConfigParams
        :param inputs: task inputs
        :type inputs: TaskInputs
        :return: the context
        :rtype: str
        """

    @abstractmethod
    def build_openai_code_inputs(self, params: ConfigParams, inputs: TaskInputs) -> dict:
        """Method to build the variables that will be accessible in the generated code.

        :param params: task params
        :type params: ConfigParams
        :param inputs: task inputs
        :type inputs: TaskInputs
        :return: the input dict that will be accessible in the generated code
        :rtype: dict
        """

    @abstractmethod
    def build_task_outputs(self, params: ConfigParams, inputs: TaskInputs,
                           code_outputs: dict, generated_code: str) -> dict:
        """Method to build the task outputs resources based on the generated code results.

        :param params: task params
        :type params: ConfigParams
        :param inputs: task inputs
        :type inputs: TaskInputs
        :param code_outputs: the outputs of the generated code
        :type code_outputs: dict
        :param generated_code: the generated code
        :type generated_code: str
        :return: the task outputs
        :rtype: dict
        """

    def describe_inputs_for_context(self, inputs: dict) -> str:
        """Method that is automatically called by the task to describe the inputs that are accessible in the generated code.
        This method can be overrided to change the way of describing the inputs.
        :param inputs: transformed inputs generated by build_openai_code_inputs method
        :type inputs: dict
        :return: the description of the inputs to be passed to the context
        :rtype: str
        """
        OpenAiHelper.describe_inputs_for_context(inputs)

    def describe_outputs_for_context(self, outputs_specs: Dict[str, type]) -> str:
        """Method to describe the outputs that will be generated by the generated code.

        :param outputs_specs: specs of the outputs that needs to be generated by the code.
        The key is the name of the output, the value is the type of the output.
        :type outputs_specs: Dict[str, type]
        :return: the description of the outputs to be passed to the context
        :rtype: str
        """
        OpenAiHelper.describe_outputs_for_context(outputs)

    def run(self, params: ConfigParams, inputs: TaskInputs) -> TaskOutputs:

        chat: OpenAiChat = params.get_value('prompt')

        # all variable accessible in the generated code
        input_variables = self.build_openai_code_inputs(params, inputs)

        # retrieve the main context
        context = self.get_context(params, inputs)
        # Add information about the input variables
        context += f"\n{self.describe_inputs_for_context(input_variables)}"

        # Store the context in the chat object
        chat.set_context(context)

        # only call open ai if the last message is from the user
        if chat.last_message_is_user():
            # create the completion
            self.log_info_message('Generating code snippet...')
            chat = OpenAiHelper.call_gpt(chat)

        # save the new config with the new prompt
        params.set_value('prompt', chat)
        params.save_params()

        code = chat.get_last_assistant_message(extract_code=True)
        if code is None:
            raise Exception("No code generated by OpenAI")

        self.log_info_message('Code generated by OpenAI: ' + code)

        # execute the live code
        self.log_info_message('Executing the code snippet...')
        outputs = LiveCodeHelper.run_python_code(code, input_variables)

        return self.build_task_outputs(params, inputs, outputs, code)

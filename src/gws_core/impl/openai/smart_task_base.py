

from abc import abstractmethod
from typing import Any, Dict, List, Type

from gws_core.config.config_params import ConfigParams
from gws_core.config.config_types import ConfigSpecs
from gws_core.impl.live.helper.live_code_helper import LiveCodeHelper
from gws_core.impl.openai.open_ai_chat import OpenAiChat
from gws_core.impl.openai.open_ai_chat_param import OpenAiChatParam
from gws_core.impl.openai.open_ai_helper import OpenAiHelper
from gws_core.impl.text.text import Text
from gws_core.io.io_spec import OutputSpec
from gws_core.task.task import Task
from gws_core.task.task_io import TaskInputs, TaskOutputs


class SmartTaskBase(Task):
    """Base class to apply transformation to resources based on a prompt and AI (openAI).
    This will ask the AI to generate a code and then execute it.


    This class need a context to tell the AI what is the goal of the task, what are the inputs and outputs...
    To build the context, you must overide the following methods (see build_context method to view the context structure):

    - build_main_context: method to build the context of the openAI chat. This context is used to give precise information to the AI to generate the code you want.
    - build_code_inputs: method to build the variables that will be accessible in the generated code.
    - get_code_expected_output_types: method to describe the output names (keys) and types (values) expected by the generated code.
    - get_available_package_names: method to retrieve the package names that can be used by the AI in the generated the code.

    Once the code is generated, it is executed and the outputs are retrieved. You will need to convert the code
    outputs to task outputs. To do so, you must overide the following method:

    - build_task_outputs: method to build the task outputs resources based on the generated code outputs.
    """

    generated_code_output = OutputSpec(
        Text, human_name='Generated code',
        short_description='Modified generated code that can be used in a python live task directly.')

    config_specs: ConfigSpecs = {
        'prompt': OpenAiChatParam()
    }

    VAR_PY_INTRO = "You are a developer assistant that generate code in python."
    VAR_R_INTRO = "You are a developer assistant that generate code in R."
    VAR_INPUTS = "$INPUTS$"
    VAR_OUTPUTS = "$OUTPUTS$"
    VAR_CODE_RULES = "$CODE_RULES$"

    @abstractmethod
    def build_main_context(self, params: ConfigParams, task_inputs: TaskInputs,
                           code_inputs: Dict[str, Any]) -> str:
        """Method to build the context of the openAI chat. This should define the main goal of the task.
        You can use variable in the context that will be replaced by the task.
        Available variables are :
        - VAR_PY_INTRO : Intro for python code generation
        - VAR_R_INTRO : Intro for R code generation
        - VAR_INPUTS : Description of the inputs based on build_code_inputs() result
        - VAR_OUTPUTS : Description of the outputs based on get_code_expected_output_types result
        - VAR_CODE_RULES : Description of the code rules (packages, imports ...)

        Thoses variable are attribute (self.VAR_PY_INTRO). The recommended order is :
        - INTRO
        - Text to explain the goal of the task (Ex: "The code purpose is to generate a plotly express figure from a DataFrame.")
        - INPUTS
        - OUTPUTS
        - CODE_RULES

        You can insert text after a variable to add more information, like :
        - VAR_INPUTS + 'The dataframe has ' + str(table.nb_rows) + ' rows and ' + str(table.nb_columns) + ' columns.'
        - VAR_OUTPUTS + 'Only build the figure object, do not display the figure using 'show' method.'

        :param params: task params
        :type params: ConfigParams
        :param inputs: task inputs
        :type inputs: TaskInputs
        :param code_inputs: transformed inputs generated by build_code_inputs method
        :type code_inputs: dict
        :return: the context
        :rtype: str
        """

    @abstractmethod
    def build_code_inputs(self, params: ConfigParams, task_inputs: TaskInputs) -> dict:
        """Method to build the variables that will be accessible in the generated code.
        It is recommended to use known object types for the inputs, like dict, list, Dataframe, int ...
        so the AI can understand the structure of the input.

        :param params: task params
        :type params: ConfigParams
        :param inputs: task inputs
        :type inputs: TaskInputs
        :return: the input dict that will be accessible in the generated code
        :rtype: dict
        """

    @abstractmethod
    def get_code_expected_output_types(self) -> Dict[str, Type]:
        """Method to describe the output names (keys) and types (values) expected by the generated code.
        The AI will receive instructions to generate code that returns variables with the specified names and types.
        This is used by build_task_outputs to retrieve the output of the generated code.

        :return: the output specs
        :rtype: Dict[str, Type]
        """
        return {}

    @abstractmethod
    def get_available_package_names(self) -> List[str]:
        """Method to retrieve the package names that can be used by the AI in the generated the code.
        The package must be installed in the lab.
        This is used by build_code_context to retrieve the version of the package are write a text to describe the packages.
        Return empty list if no package is needed.

        :return: the list of package names
        :rtype: List[str]
        """
        return []

    @abstractmethod
    def build_task_outputs(self, code_outputs: Dict[str, Any], generated_code: str,
                           params: ConfigParams, task_inputs: TaskInputs) -> dict:
        """Method to build the task outputs resources based on the generated code outputs.

        :param code_outputs: the outputs of the generated code
        :type code_outputs: dict
        :param generated_code: the generated code
        :type generated_code: str
        :param params: task params
        :type params: ConfigParams
        :param inputs: task inputs
        :type inputs: TaskInputs
        :return: the task outputs
        :rtype: dict
        """

    def build_inputs_context(self, code_inputs: Dict[str, Any]) -> str:
        """Method that is automatically called by the task to describe the inputs that are accessible in the generated code.
        This method can be overrided to change the way of describing the inputs, or to add more information
        (like the number of rows for a dataframe, the structure of a json ...)
        :param inputs: transformed inputs generated by build_code_inputs method
        :type inputs: dict
        :return: the description of the inputs to be passed to the context
        :rtype: str
        """
        if len(code_inputs) == 0:
            return ""
        return OpenAiHelper.describe_inputs_for_context(code_inputs)

    def build_outputs_context(self) -> str:
        """Method that is automatically called by the task to describe the outputs that are accessible in the generated code.
        This method can be overrided to change the way of describing the outputs.
        :param outputs_specs: the outputs specs
        :type outputs_specs: Dict[str, Type]
        :return: the description of the outputs to be passed to the context
        :rtype: str
        """
        output_specs = self.get_code_expected_output_types()
        if len(output_specs) == 0:
            return ""
        return OpenAiHelper.describe_outputs_for_context(output_specs)

    def build_code_rules_context(self, pip_package_names: List[str] = None) -> str:
        """Method to define the context rules for the code generation, so the generated code is executable.
        This method can be overrided to change the way of describing the code context.
        :param pip_package_names: list of available package that can be used in the generated code. The version of the package will be automatically retrieved, defaults to None
        :type pip_package_names: List[str], optional
        :return: the context
        :rtype: str
        """
        return OpenAiHelper.get_code_context(pip_package_names)

    def build_context(self, params: ConfigParams, task_inputs: TaskInputs,
                      code_inputs: Dict[str, Any]) -> str:
        """Method that is automatically called by the task to build the context.
        This method can be overided to change the way of describing the context.

        :param params: task params
        :type params: ConfigParams
        :param inputs: task inputs
        :type inputs: TaskInputs
        :return: the context
        :rtype: str
        """
        # retrieve the main context
        main_context = self.build_main_context(params, task_inputs, code_inputs)

        if not main_context or len(main_context) == 0:
            raise Exception("The main context must be defined")

        if self.VAR_INPUTS in main_context:
            inputs = self.build_inputs_context(code_inputs) or ''
            main_context = main_context.replace(self.VAR_INPUTS, inputs + ' ')

        if self.VAR_OUTPUTS in main_context:
            outputs = self.build_outputs_context() or ''
            main_context = main_context.replace(self.VAR_OUTPUTS, outputs + ' ')

        if self.VAR_CODE_RULES in main_context:
            code_rules = self.build_code_rules_context(self.get_available_package_names()) or ''
            main_context = main_context.replace(self.VAR_CODE_RULES, code_rules + ' ')

        return main_context

    def run(self, params: ConfigParams, inputs: TaskInputs) -> TaskOutputs:

        chat: OpenAiChat = params.get_value('prompt')

        # all variable accessible in the generated code
        code_inputs = self.build_code_inputs(params, inputs)

        if chat.last_message_is_user():
            # retrieve the main context
            context = self.build_context(params, inputs, code_inputs)

            # Store the context in the chat object
            chat.set_context(context)

            # only call open ai if the last message is from the user
            # create the completion
            self.log_info_message('Generating code snippet...')
            chat.call_gpt()

            # save the new config with the new prompt
            params.set_value('prompt', chat)
            params.save_params()
        else:
            self.log_info_message('The last message is not from the user, no need to call openAI')

        code = chat.get_last_assistant_message(extract_code=True)
        if code is None:
            raise Exception("No code generated by OpenAI")

        self.log_info_message('Code generated by OpenAI: ' + code)

        # execute the live code
        self.log_info_message('Executing the code snippet...')
        outputs = LiveCodeHelper.run_python_code(code, code_inputs)

        return self.build_task_outputs(outputs, code, params, inputs)
